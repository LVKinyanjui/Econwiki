{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be the frontend to interact with our rag application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01HXCGMB7AARG4J82D47JP7FH0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import FailedPrecondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01HX56G6P8DTZT2RW97RC1MCJ2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# INITIALIZATION AND CONFIGURATION\n",
    "# Gemini\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Pinecone initialization\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'), environment='gcp-starter')\n",
    "index_name = pc.list_indexes()[0]['name']\n",
    "index = pc.Index(index_name)\n",
    "namespace = 'Econwiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01HX56RTFH336ZM4CZFNWYJTXV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is life?\"\n",
    "def pinecone_query(query: str, with_expansion: bool = False) -> str:\n",
    "    # TODO: Introduce more parameters rather than rely on  hardcoded values\n",
    "    try:\n",
    "        if with_expansion:\n",
    "            system_prompt = f\"\"\"\n",
    "                You are a useful informative assistant\n",
    "                You are to be issued with a question\n",
    "                You will create similar questions \n",
    "                    similar scope, similar topics and themes,\n",
    "                The point is to expound on the original question\n",
    "                    with related questions\n",
    "                No need to write 'Similar questions'\n",
    "                or do extensive formatting\n",
    "\n",
    "                The question is attached after this.\n",
    "\n",
    "            \"\"\"\n",
    "            query = system_prompt + query\n",
    "\n",
    "        query_vector_ = genai.embed_content(content= query,\n",
    "                                            model='models/embedding-001')\n",
    "        query_vector = query_vector_['embedding']\n",
    "\n",
    "        res = index.query(\n",
    "            top_k=5,\n",
    "            vector=query_vector,\n",
    "            include_metadata=True,\n",
    "            namespace=namespace\n",
    "        )\n",
    "\n",
    "        return '\\n\\n'.join([match['metadata']['text'] for match in res['matches']])\n",
    "    \n",
    "    except FailedPrecondition:\n",
    "        # TODO: Raise descriptive gradio error\n",
    "        raise gr.Error(\"Server may be using a VPN. Please disconnect and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01HXCNDKPWJS76R68WAA2ZAV3D",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# # Querying with Expansion\n",
    "# # Used to refine retrieval by generating related queries that may yield a better result\n",
    "# def pinecone_query_with_expansion(query):\n",
    "#     system_prompt = f\"\"\"\n",
    "#         You are a useful informative assistant\n",
    "#         You are to be issued with a question\n",
    "#         You will create similar questions \n",
    "#             similar scope, similar topics and themes,\n",
    "#         The point is to expound on the original question\n",
    "#             with related questions\n",
    "#         No need to write 'Similar questions'\n",
    "#         or do extensive formatting\n",
    "\n",
    "#         The question is attached after this.\n",
    "\n",
    "#     \"\"\"\n",
    "#     augmented_query = system_prompt + query\n",
    "#     res = model.generate_content(augmented_query)\n",
    "#     return res.text\n",
    "\n",
    "# pprint(pinecone_query_with_expansion('What is my name?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01HXCHPSZH3ZAXDCN1MJ50D44D",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer_query(context: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "        You are provided with a text to summarize\n",
    "        There may be a main topic or theme that you can identify\n",
    "        Synthesize the various aspects of the texts to create a concise yet informative summary\n",
    "        The text follows below:\n",
    "\n",
    "        {context}\n",
    "\n",
    "    \"\"\"\n",
    "    res = model.generate_content(prompt)\n",
    "    return res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01HX57ACA5ZK8QDM11RSFHFXSB",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.7.1, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# GRADIO APP\n",
    "with gr.Blocks() as demo:\n",
    "    input = gr.Textbox('what is the role of the IMF in Kenya?', label='Query', placeholder='Enter your question here.')\n",
    "    button = gr.Button('Submit')\n",
    "\n",
    "    llm_output = gr.Markdown(label=\"Answer\")\n",
    "    expand_button = gr.Button('Expand Answer', value=True)      # Passes True value to query function to enable expaned query\n",
    "    \n",
    "    with gr.Accordion(\"Retrieved Content\", open=False):\n",
    "        retrieved_output = gr.Markdown()\n",
    "\n",
    "    # button.click(fn=pinecone_query, inputs=[input], outputs=[retrieved_output])\n",
    "    # Multiple triggers\n",
    "    gr.on(triggers=[button.click, input.submit],\n",
    "          fn=pinecone_query,\n",
    "          inputs=[input], \n",
    "          outputs=[retrieved_output],\n",
    "          )\n",
    "    expand_button.click(fn=pinecone_query, inputs=[input, expand_button], outputs=[retrieved_output])\n",
    "    retrieved_output.change(fn=llm_answer_query, inputs=[retrieved_output], outputs=[llm_output])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "1. Query expansion does not appear to be very succesful. It does not extract the document summaries that RAPTOR produces.\n",
    "2. App control flow is such that one can only expand answer once. This should be increased by setting better event listening flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX57YZJSX65AJZCCDDSFGY5D",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
